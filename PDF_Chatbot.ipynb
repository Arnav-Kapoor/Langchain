{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5b7baa-a1d9-4b7b-8f99-812bd0676216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9670b4-57f4-416b-ad30-7750c7c61384",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(\"../musiclm research paper by google.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee07cd-3734-473b-a9be-504f4312be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5572d4f-6b58-42fa-a789-858cac60b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b7d0e6-4ace-475b-8305-9219a7b921a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=Chroma.from_documents(documents,OllamaEmbeddings(model=\"nomic-embed-text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73607afc-0ebf-4168-9e9e-2bc30bc2c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=(\"\"\" You are a question-answer assistant.\n",
    "                    Answer the questions based on the context provided.\n",
    "                    Keep the answers as accurate and concise as possible.\n",
    "                    If the answer is not present in the context then say its not available in the context.\n",
    "                    \\n\\n\n",
    "                    {context}.\"\"\")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([(\"system\",system_message),\n",
    "                                        (\"human\",\"{input}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e4815d-d20d-471b-8fc8-421cb0bbcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ffde0d-91d4-4693-81b1-38a8b1986c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_document_chain=create_stuff_documents_chain(model,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d7ffc5-8a97-4c4a-b07c-46bfd9b47e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a52f443-cd6d-43ee-bd70-d2f52ba3c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_chain=create_retrieval_chain(retriever,stuff_document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26586474-fefc-4092-a423-1db434a1656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retriver_chain.invoke({\"input\":\"can you give me summary of this document\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "effa0cb5-49e9-45ab-be36-30ee3ad3ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the MusicLM documentation:\n",
      "\n",
      "The MusicLM system generates music from text descriptions using the MusicCaps dataset, which contains 5,521 examples of music clips paired with corresponding English text descriptions. The dataset is divided into two splits: eval (2,858) and train (2,663). A balanced subset of 1,000 examples is also provided.\n",
      "\n",
      "The documentation mentions various metrics to evaluate the quality of generated music, including:\n",
      "\n",
      "1. Fr√©chet Audio Distance (FAD), which measures audio quality\n",
      "2. Adherence to text descriptions\n",
      "\n",
      "Additionally, the MusicLM system provides a genre-balanced split of the data with 1,000 examples.\n",
      "\n",
      "Please note that this is a summary of the provided document, and more detailed information can be found in the original text.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde5821-7f71-4f7f-8472-c99974433cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
