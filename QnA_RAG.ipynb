{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285384a6-4be6-43c1-bbb2-201d92ecf90d",
   "metadata": {},
   "source": [
    "##### QnA chatcot using RAG. context is standford lectures. this is a take home assignment for an application(Ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e671fcf7-d8fe-4891-9e22-fcc8be68e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8492115d-27ed-4237-82dc-271bc0c2f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80aff92-00b5-4fa8-92a3-14dc2aaff65c",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5226de6-9437-436b-ba8a-2683fde2d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader1=WebBaseLoader(web_paths=(\"https://stanford-cs324.github.io/winter2022/lectures/introduction/\",),\n",
    "                    bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"main-content-wrap\")))) \n",
    "loader2=WebBaseLoader(web_paths=(\"https://stanford-cs324.github.io/winter2022/lectures/legality/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"main-content-wrap\"))))\n",
    "loader3=WebBaseLoader(web_paths=(\"https://stanford-cs324.github.io/winter2022/lectures/modeling/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"main_content-wrap\"))))\n",
    "loader4=WebBaseLoader(web_paths=(\"https://stanford-cs324.github.io/winter2022/lectures/training/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"main-content-wrap\"))))\n",
    "### we are using 4 lectures: intro, legality, modeling and training. \n",
    "### since all the content was inside the main class \"main-content-wrap\" we used that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2aea361-9e32-4238-9dc5-c9e016b41cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders=[loader1,loader2,loader3,loader4] #array of loaders to work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d211aa3-92e7-4348-bcc3-2cf1fef59ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load()) #loading documents together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da51bc-0ad4-4ec5-b7c3-83b3713cd729",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683f719-40c3-4a44-bd2b-522c39de258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ece27eb7-3f41-46be-9237-fa5b221bdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split=splitter.split_documents(docs) # splitting documents into chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15b542be-2cc2-4c5d-8ba8-ca9cfc71a174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37e16600-52c2-477c-a9a6-9661760efafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LecturesIntroduction \\\\[\\\\newcommand{\\\\sV}{\\\\mathcal{V}} \\\\newcommand{\\\\nl}[1]{\\\\textsf{#1}} \\\\newcommand{\\\\generate}[1]{\\\\stackrel{#1}{\\\\rightsquigarrow}}\\\\]Welcome to CS324! This is a new course on understanding and developing large language models.What is a language model?A brief historyWhy does this course exist?Structure of this course  What is a language model?The classic definition of a language model (LM) is a probability distribution over sequences of tokens. Suppose we have a vocabulary \\\\(\\\\sV\\\\) of a set of tokens. A language model \\\\(p\\\\) assigns each sequence of tokens \\\\(x_1, \\\\dots, x_L \\\\in \\\\sV\\\\) a probability (a number between 0 and 1):\\\\[p(x_1, \\\\dots, x_L).\\\\]The probability intuitively tells us how “good” a sequence of tokens is. For example, if the vocabulary is \\\\(\\\\sV = \\\\{ \\\\nl{ate}, \\\\nl{ball}, \\\\nl{cheese}, \\\\nl{mouse}, \\\\nl{the} \\\\}\\\\), the language model might assign (demo):\\\\[p(\\\\nl{the}, \\\\nl{mouse}, \\\\nl{ate}, \\\\nl{the}, \\\\nl{cheese}) = 0.02,\\\\] \\\\[p(\\\\nl{the}, \\\\nl{cheese}, \\\\nl{ate}, \\\\nl{the},'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd340082-c550-4d40-8fd7-2beb6355d765",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59664c4d-e14d-41f3-8073-904135d47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=(\"\"\" You are a question-answer assistant.\n",
    "                    Answer the questions based on the context provided or from the chat history.\n",
    "                    Keep the answers as accurate and concise as possible.\n",
    "                    If the answer is not present in the context or chat history then say its not available in the context.\n",
    "                    \\n\\n\n",
    "                    {context}.\"\"\")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([(\"system\",system_message),\n",
    "                                         MessagesPlaceholder(\"chat_history\"),\n",
    "                                        (\"human\",\"{input}\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d05bbc6a-7ceb-46b3-9489-83f1d8e022dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "533b673a-1c4a-4c99-8a76-d20e3ad2870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_doc_chain=create_stuff_documents_chain(model,prompt) #creating stuff document chain or basically chaining llm and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641b2bb-1665-44d0-a85d-377a6178b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage=Chroma.from_documents(split,OllamaEmbeddings(model=\"nomic-embed-text\"), persist_directory=\"vector_store\",collection_name=\"qna_embeddings\") #initializing our vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb63636-a242-43c1-9ae1-8867f95b6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95e30648-d3bc-4a0f-b8ea-bdd1a510b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt for chat history\n",
    "\n",
    "system=\"\"\" Given a chat history and the latest user question \n",
    "    which might reference context in the chat history, \n",
    "    formulate a standalone question which can be understood \n",
    "    without the chat history. Do NOT answer the question, \n",
    "    just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "history_prompt=ChatPromptTemplate.from_messages([(\"system\",system),\n",
    "                                  MessagesPlaceholder(\"chat_history\"),\n",
    "                                  (\"human\",\"{input}\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa9d9ae2-b844-4925-b9b4-23ddf0f812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=create_history_aware_retriever(model,retriever,history_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "912749eb-6fec-464d-8d68-9947763181be",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chain=create_retrieval_chain(retriever,stuff_doc_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b75083-7bbb-48be-8df9-a31f45ecd628",
   "metadata": {},
   "source": [
    "## managing chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d72c233-469a-43c6-adc4-de4523f3ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def get_session_history(session_id)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48859bde-4dcc-4505-ab55-ed4de306dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain=RunnableWithMessageHistory(retriever_chain,get_session_history, input_messages_key=\"input\",\n",
    "                                     history_messages_key=\"chat_history\", output_messages_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c302dab-dc0c-49a8-ac60-4c47f3d8d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"abcd\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b189e2e6-7cec-4c8f-bc63-2f87e8febd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.core:Parent run 3708e5ce-e139-4e0b-b574-5d0cb8439bcc not found for run 52b752bc-07ec-4926-995c-cdf916381f14. Treating as a root run.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What are some milestone model architectures and papers in the last few years?\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc70d6ca-9595-4a58-b58c-452c6cedf498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here are some milestone model architectures and papers in the last few years:\n",
      "\n",
      "* Recurrent Neural Networks (RNNs), including Long Short Term Memory (LSTMs), allowed the conditional distribution of a token \\(x_i\\) to depend on the entire context \\(x_{1:i-1}\\) (effectively \\(n = \\infty\\)), but these were hard to train.\n",
      "* Transformers are a more recent architecture (developed for machine translation in 2017) that again returned to having fixed context length \\(n\\), but were much easier to train (and exploited the parallelism of GPUs). Also, \\(n\\) could be made “large enough” for many applications (GPT-3 used \\(n = 2048\\)).\n",
      "* Some notable papers in recent years include:\n",
      "\t+ \"Exploring the Limits of Language Modeling\" by R. Józefowicz, Oriol Vinyals, M. Schuster, Noam M. Shazeer, and Luke Zettlemoyer (2016)\n",
      "\t+ \"Attention is All You Need\" by Vaswani et al. (2017)\n",
      "\t+ \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" by Devlin et al. (2019)\n",
      "\n",
      "Please note that this information is based on the provided context and might not be a comprehensive list of all milestone model architectures and papers in recent years.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c81b3c0-6ce1-4666-8a4f-d38e793df6b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93dd57ed-6732-4777-9086-31d5e6d00494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n"
     ]
    }
   ],
   "source": [
    "for docs in response[\"context\"]:\n",
    "    print(docs.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a8d8395-61c7-4fb4-8b88-e99478050475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.core:Parent run 6ee532a3-e20f-4662-a316-743320e37384 not found for run d2f77d58-f4ba-4066-a681-dbf34696d177. Treating as a root run.\n"
     ]
    }
   ],
   "source": [
    "response2=rag_chain.invoke({\"input\":\"what are the types of law?\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "615c32cf-9651-4b3e-89de-8e15d815f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The provided context mentions that there are different types of law, including:\\n\\n* Common law (judiciary): Also known as case law, common law is based on judges referencing previous similar cases and making a ruling (precedent).\\n* Statutory law (legislature): Also known as written law, statutory law is produced by government agencies through the legislative process (e.g., congress passing a bill).\\n* Regulatory law (executive): Also known as administrative law, this is law that is created by the executive branch of government, often focusing on procedures.\\n\\nPlease let me know if you have any further questions or if there's anything else I can help with!\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47b49a04-f170-439f-bf03-090b2dc4ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stanford-cs324.github.io/winter2022/lectures/legality/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/legality/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/legality/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/legality/\n"
     ]
    }
   ],
   "source": [
    "for docs in response2[\"context\"]:\n",
    "    print(docs.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a6f250d-11a2-4d7c-b421-a2e870f43560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.core:Parent run 071ca061-2b00-46e6-a4ac-f3ef00d901a1 not found for run 7d7f002d-8dd2-4650-b6f1-c00a9aee8567. Treating as a root run.\n"
     ]
    }
   ],
   "source": [
    "reaponse3=rag_chain.invoke({\"input\":\"can you tell me what questions did i ask before\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6d932be-f550-42d1-97a4-536891b616a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You didn\\'t ask any questions before. Your first question was \"What are some milestone model architectures and papers in the last few years?\". Then, you asked another question about the same topic, and finally, you asked \"what are the types of law?\"'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaponse3[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3236446-88b5-46e2-adc6-e2fc1765627a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "342f5072-23fc-4511-b3d2-0302eaffff2f",
   "metadata": {},
   "source": [
    "# Putting everything at one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "181f6a8f-0fad-48dd-afb9-31f997e262bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordLectureBot:\n",
    "    def __init__(self,vector_store,model=\"llama3\"):\n",
    "        self.vector_store=vector_store\n",
    "        self.llm=Ollama(model=model)\n",
    "        self.system_message=(\"\"\" You are a question-answer assistant.\n",
    "                    Answer the questions based on the context provided.\n",
    "                    Keep the answers as accurate and concise as possible.\n",
    "                    If the answer is not present in the context then say its not available in the context.\n",
    "                    \\n\\n\n",
    "                    {context}.\"\"\")\n",
    "\n",
    "        self.prompt=ChatPromptTemplate.from_messages([(\"system\",self.system_message),\n",
    "                                        (\"human\",\"{input}\")])\n",
    "        self.stuff_doc_chain=create_stuff_documents_chain(self.llm,self.prompt)\n",
    "        self.retriever=self.vector_store.as_retriever()\n",
    "        self.retriever_chain=create_retrieval_chain(self.retriever,self.stuff_doc_chain)\n",
    "        \n",
    "    def howMayIHelpYou(self,query):\n",
    "        response=self.retriever_chain.invoke({\"input\":query})\n",
    "        print(response[\"answer\"])\n",
    "        print(\"\\n\\nSources:\\n\")\n",
    "        for docs in response[\"context\"]:\n",
    "            print(docs.metadata[\"source\"])\n",
    "    \n",
    "    def addLecture(self,path):\n",
    "        loader=WebBaseLoader(web_paths=(path,),\n",
    "                    bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"main-content-wrap\"))))\n",
    "        doc=loader.load()\n",
    "        splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "        split=splitter.split_documents(doc)\n",
    "        self.retriever.vectorstore.add_documents(split)\n",
    "        self.retriever_chain=create_retrieval_chain(self.retriever,self.stuff_doc_chain)\n",
    "        print(\"Added\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26d2b853-1ac8-49b7-b672-0aa32d2b9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading vector store\n",
    "vector_store=Chroma(persist_directory=\"vector_store\",embedding_function=OllamaEmbeddings(model=\"nomic-embed-text\"),collection_name=\"qna_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606c10c2-927b-4cd7-8b80-4b4240f92b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance\n",
    "bot=StanfordLectureBot(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12510bde-3a79-4752-827d-24d5a49cb5f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, some milestone model architectures and papers in the last few years include:\n",
      "\n",
      "1. Transformers (2017): This paper introduced a new architecture for machine translation that replaced recurrent neural networks (RNNs) with self-attention mechanisms. The transformer model was more efficient and accurate than RNNs.\n",
      "\n",
      "Paper: \"Attention Is All You Need\" by Ashish Vaswani et al.\n",
      "\n",
      "2. BERT (2018): Bidirectional Encoder Representations from Transformers (BERT) is a pre-trained language model that uses a multi-layer bidirectional transformer encoder to generate contextualized representations of text.\n",
      "\n",
      "Paper: \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" by Jacob Devlin et al.\n",
      "\n",
      "3. RoBERTa (2019): Robustly Optimized BERT Pretraining Approach (RoBERTa) is an updated version of the BERT model that uses a different optimization approach and adds a few new techniques to improve performance.\n",
      "\n",
      "Paper: \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\" by Yinhan Liu et al.\n",
      "\n",
      "4. XLNet (2019): eXtra-Large Language Model (XLNet) is a pre-trained language model that uses a different training approach than BERT and RoBERTa, and achieves state-of-the-art results on many natural language processing tasks.\n",
      "\n",
      "Paper: \"XLNet: Inducing Extra-Lingual Knowledge for Natural Language Processing\" by Zhilin Yang et al.\n",
      "\n",
      "5. T5 (2020): Text-to-Text Transfer with Cross-Attention without Target Label is a pre-trained text-to-text model that uses a different approach than BERT and XLNet, and achieves state-of-the-art results on many natural language processing tasks.\n",
      "\n",
      "Paper: \"T5: Text-to-Text Transfer with Cross-Attention without Target Label\" by Jean-Baptiste Grave et al.\n",
      "\n",
      "6. DALL-E (2021): DALL-E is a text-to-image model that uses a transformer-based architecture to generate images from text prompts, and achieves state-of-the-art results on many image generation tasks.\n",
      "\n",
      "Paper: \"DALL-E: A Text-to-Image Model with Attention\" by Loganeng et al.\n",
      "\n",
      "These are just a few examples of milestone model architectures and papers in the last few years. There have been many other important developments in natural language processing research, and I'm happy to provide more information if you're interested!\n",
      "\n",
      "\n",
      "Sources:\n",
      "\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n"
     ]
    }
   ],
   "source": [
    "#passing query\n",
    "bot.howMayIHelpYou(\"What are some milestone model architectures and papers in the last few years?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "848f29e5-775f-428e-ae7a-8cf262fe85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added\n"
     ]
    }
   ],
   "source": [
    "bot.addLecture(\"https://stanford-cs324.github.io/winter2022/lectures/capabilities/\") #capabilities lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "086720bd-4188-485a-b653-6040977b4e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The course exists because the size of neural language models has skyrocketed in recent years due to major hardware advances (e.g., GPUs) and the rise of deep learning in the 2010s. This increase in size has led to emergent behavior, producing new capabilities and societal impact.\n",
      "\n",
      "Penn Tree Bank is a dataset used for natural language processing tasks, particularly parsing and part-of-speech tagging.\n",
      "\n",
      "\n",
      "Sources:\n",
      "\n",
      "https://stanford-cs324.github.io/winter2022/lectures/capabilities/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/introduction/\n",
      "https://stanford-cs324.github.io/winter2022/lectures/legality/\n"
     ]
    }
   ],
   "source": [
    "bot.howMayIHelpYou(\"what is Penn Tree Bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98397e-4e25-44dc-baf8-ba95875a83e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
